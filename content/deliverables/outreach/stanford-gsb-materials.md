# Stanford GSB Promotion Materials

## Research Summary (for GSB channels)

**Title:** What's Needed to Unlock the Full Potential of AI Agents?
**Course:** GSBGEN 390 - Individual Research
**Term:** Autumn 2025
**Authors:** Fernando Torres & Shekhar Bhende (MSx '26)
**Faculty Sponsor:** Prof. Scott J. Brady

---

### Key Findings

AI agents represent one of the most promising frontiers in artificial intelligence, yet a stark gap persists between demonstrated capabilities and production deployment. Through 10 weeks of rigorous research at Stanford GSB—including 36 expert interviews, 5 industry conferences, and 3 functional prototypes—we discovered that production deployment is fundamentally an engineering problem, not an AI problem.

Our research reveals a counterintuitive insight: models contribute only 30-40% to agent success; the remaining 60-70% comes from framework architecture, system integration, and evaluation infrastructure. System integration emerged as the dominant challenge, appearing in 92% of our sources and consuming 40-50% of all deployment time. Perhaps most critically, 90% of enterprise pilots fail not due to technical limitations but because organizations cannot define ROI, forecast costs, or manage stakeholder expectations around probabilistic systems.

The companies succeeding with AI agents are not chasing better models—they are building better systems. Our research identifies significant infrastructure opportunities in evaluation frameworks, memory architectures, and vertical-specific integration that will unlock the next wave of value creation in agentic AI. These findings have immediate implications for enterprises evaluating agent deployment, venture investors assessing the market, and practitioners building production systems.

---

## Potential GSB Channels

### 1. MSx Newsletter

- **Audience:** MSx cohort, alumni, and prospective students
- **Format:** Feature article or research spotlight
- **Timing:** Winter 2026 newsletter edition
- **Contact:** MSx Communications Team

### 2. GSB Research Portal

- **Audience:** Academic community, industry researchers
- **Format:** Research paper listing with abstract
- **Timing:** Upon faculty sponsor approval
- **Contact:** Research & Publications Office

### 3. GSBGEN 390 Showcase

- **Audience:** Faculty, current 390 researchers, prospective students
- **Format:** Presentation or poster session
- **Timing:** End of Autumn Quarter or Winter Quarter event
- **Contact:** RDI Program Coordinator

### 4. Stanford Alumni Network

- **Audience:** GSB alumni in tech, AI, and enterprise software
- **Format:** Alumni event presentation or webinar
- **Timing:** Q1 2026
- **Contact:** Alumni Relations

### 5. GSB Insights Blog

- **Audience:** General business community, prospective applicants
- **Format:** Blog post with key findings
- **Timing:** Upon completion of approvals
- **Contact:** GSB Communications

### 6. Stanford HAI (Human-Centered AI Institute)

- **Audience:** Stanford AI research community
- **Format:** Research summary or cross-listing
- **Timing:** Upon publication
- **Contact:** HAI Communications

---

## Materials Needed

### 1-Pager Executive Summary

**What's Needed to Unlock the Full Potential of AI Agents?**

_GSBGEN 390 Research | Autumn 2025_
_Fernando Torres & Shekhar Bhende (MSx '26) | Faculty Sponsor: Prof. Scott J. Brady_

**The Problem:** AI agents demonstrate impressive capabilities yet 90% of enterprise pilots fail to reach production. What prevents agents from transitioning from demos to reliable enterprise tools?

**Our Approach:**

- 36 expert interviews with practitioners actively deploying agentic workflows
- 5 industry conferences in San Francisco and Palo Alto
- 3 functional prototypes built to validate findings

**Key Discoveries:**

| Finding                                                            | Data Point                                                                |
| ------------------------------------------------------------------ | ------------------------------------------------------------------------- |
| Production AI agents are an engineering problem, not an AI problem | Models contribute only 30-40% to success                                  |
| System integration dominates deployment effort                     | Appears in 92% of sources; consumes 40-50% of deployment time             |
| Framework abandonment is systematic                                | 80-90% of teams abandon a popular AI agent framework for custom solutions |
| Business case failure precedes technical failure                   | 90% of pilots fail due to undefined ROI, not technology                   |
| Context windows require engineering, not expansion                 | 40% utilization threshold regardless of window size                       |

**Implications:**

- Enterprise teams should invest in integration infrastructure, not just AI capabilities
- Evaluation methodology gaps represent a major market opportunity
- Vertical specialization will dominate over horizontal platforms
- The bottleneck is engineering, economics, and organizational readiness—not model intelligence

**Contact:** Fernando Torres (ftn@stanford.edu) | Shekhar Bhende (shekharb@stanford.edu)

---

### Slide Deck Outline

**Slide 1: Title**

- What's Needed to Unlock the Full Potential of AI Agents?
- GSBGEN 390 Individual Research | Autumn 2025
- Fernando Torres & Shekhar Bhende (MSx '26)
- Faculty Sponsor: Prof. Scott J. Brady

**Slide 2: The Challenge**

- 90% of AI agent pilots fail to reach production
- Demos impress, but production conversion remains elusive
- Research question: What prevents transition from demo to production?

**Slide 3: Research Methodology**

- 36 expert interviews (enterprise platforms, coding agents, vertical SaaS, framework companies)
- 5 industry conferences (Alibaba Qwen, Production Agents Summit, an AI autonomous agent company Fireside, Project Nanda)
- 3 functional prototypes (Shopping Agent, Repo Patcher, Good Agents)

**Slide 4: Initial Hypotheses**

- System integration as major blocker
- Context management as unsolved problem
- Model capabilities as primary bottleneck
- Enterprise governance as secondary concern
- Framework ecosystem needs maturation

**Slide 5: The Fundamental Insight**

- Production AI agents are an engineering problem, not an AI problem
- Models: 30-40% contribution
- Framework/architecture/integration: 60-70% contribution
- Quote: "The framework, the whole system you build upon the model is much more important than the model itself"

**Slide 6: Key Pattern 1 - Integration Dominates**

- Appears in 92% of sources
- Consumes 40-50% of deployment time
- Successful deployments treat integration as competitive moat
- Custom connectors, authentication handling, browser automation

**Slide 7: Key Pattern 2 - Framework Abandonment**

- 80-90% of production teams abandon a popular AI agent framework
- Bloat, 3-4x slower performance, loss of control
- Validated in our Shopping Agent prototype
- Paradox: prototyping accelerators become production obstacles

**Slide 8: Key Pattern 3 - The 70% Demo Threshold**

- 70% reliability creates impressive demos but fails in production
- Expectation mismatch: probabilistic vs deterministic systems
- Architectural solutions: state machines, verification phases, risk-based escalation

**Slide 9: Key Pattern 4 - Context Management**

- 40% context utilization rule contradicts vendor narratives
- MCP accuracy drops to 30% beyond 25 tools
- Solutions: notes summarization, just-in-time retrieval, dual memory architecture

**Slide 10: Critical Takeaway - Economics Block First**

- Business case failure precedes technical failure
- Cost unpredictability (token pricing confusion)
- Enterprises willing to pay $400-750/month but need guarantees
- "Handoff rate" as the right success metric

**Slide 11: Hypothesis Evolution**

- CONFIRMED: Integration, Context Management, Probabilistic Systems, Framework Fragmentation
- INVALIDATED: Model capabilities as primary blocker, Enterprise governance as secondary

**Slide 12: Future Opportunities**

- Evaluation-as-a-Service ($10B+ market opportunity)
- Enterprise Memory Systems
- Context Engineering Services
- MCP Specificity Layer

**Slide 13: Strategic Predictions**

- Vertical specialization will dominate
- Framework abandonment will accelerate
- Coding agents remain exceptional through 2027
- Small model constellations replace single frontier models

**Slide 14: Conclusion**

- The bottleneck is not AI—it's infrastructure, economics, and organizational readiness
- Agents are 30-40% model capability and 60-70% system architecture
- The opportunity is in the 60-70%, not the 30-40%

**Slide 15: Acknowledgments & Contact**

- 36 practitioners who shared insights
- 5 conference organizers
- Prof. Scott J. Brady
- Contact information

---

### Social Post for GSB Account

**Option 1 - LinkedIn/Twitter (Long Form)**

New research from Stanford GSB reveals why 90% of AI agent pilots fail—and it's not what you'd expect.

MSx students Fernando Torres and Shekhar Bhende conducted 36 expert interviews, attended 5 industry conferences, and built 3 prototypes to answer: What prevents AI agents from going from demo to production?

The surprising finding: Models contribute only 30-40% to agent success. The remaining 60-70% comes from framework architecture, system integration, and business case clarity.

Key discoveries:

- 92% of sources cite system integration as the dominant challenge
- 80-90% of production teams abandon popular frameworks like a popular AI agent framework
- 40-50% of deployment time is spent on integration—not AI development
- Business case failure precedes technical failure

The implication: Companies succeeding with AI agents aren't chasing better models. They're building better systems.

Full research: [LINK]

#StanfordGSB #AIAgents #MSx #Research

**Option 2 - Short Form (Twitter/X)**

New GSB research: 90% of AI agent pilots fail to reach production.

But it's not a model problem.

36 interviews + 5 conferences + 3 prototypes = one insight:

Agents are 30-40% model, 60-70% system architecture.

The bottleneck is engineering and economics, not AI intelligence.

#StanfordGSB #AIResearch

**Option 3 - Instagram/Visual Platform**

What does it take to make AI agents work in the real world?

MSx '26 students Fernando Torres and Shekhar Bhende spent 10 weeks finding out.

Their research for GSBGEN 390 uncovered that the biggest barrier isn't AI capability—it's everything else: integration, frameworks, and business economics.

The data point that changed everything: Models only matter 30-40%. Systems matter 60-70%.

Read more: [LINK]

#StanfordGSB #MSx2026 #AIResearch #TechAtGSB

---

## Permissions & Approvals

- [ ] Faculty sponsor approval (Prof. Scott J. Brady)
- [ ] GSB Communications review
- [ ] Research office clearance
- [ ] Interview participant consent for public quotes (where applicable)
- [ ] Review for confidential information (company names, sensitive data)

---

## Timeline

| Milestone                           | Target Date           | Notes                         |
| ----------------------------------- | --------------------- | ----------------------------- |
| Complete research and final report  | December 2025         | GSBGEN 390 submission         |
| Faculty sponsor review              | December 2025         | Prof. Brady approval          |
| GSB Communications contact          | January 2026          | Initial outreach              |
| MSx Newsletter submission           | January 2026          | Winter edition deadline       |
| GSBGEN 390 Showcase (if applicable) | January-February 2026 | Coordinate with RDI           |
| GSB Insights blog submission        | February 2026         | After approvals               |
| Alumni webinar/event                | Q1 2026               | Alumni Relations coordination |

---

## Additional Notes

### Research Differentiators for GSB Promotion

1. **Practitioner-focused methodology**: Unlike academic research, this study prioritized builders with production deployments over theorists
2. **Prototype validation**: Built 3 working systems to empirically validate interview findings
3. **Quantified insights**: Specific data points (92%, 80-90%, 30-40%) provide concrete takeaways
4. **Actionable implications**: Direct relevance for enterprise AI strategy, venture investment, and engineering teams

### Potential Media/Press Interest

The counterintuitive finding that models are "good enough" and the real bottleneck is infrastructure may attract technology media coverage. Consider coordinating with GSB Communications on any external press inquiries.

### Related Stanford Entities

- Stanford HAI (Human-Centered AI Institute)
- Stanford d.school (for design methodology aspects)
- Stanford Engineering (cross-disciplinary interest)
- Stanford Technology Ventures Program (STVP)
