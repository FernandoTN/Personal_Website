# Publication Cross-Reference Index

**AI Agents Research Publishing Project**
**Generated: December 3, 2025**
**Total Publications: 25**
**Total Topics Indexed: 32**

---

## Publications by Theme

### Phase 1: Anchor (Publication 1)

| Pub # | Title                                | Related Posts | Key Topics                                                                            |
| ----- | ------------------------------------ | ------------- | ------------------------------------------------------------------------------------- |
| 1     | AI Agents Research Overview (Anchor) | 2-25          | All themes, 90% pilot failure, 30-40% model contribution, 60-70% framework importance |

### Phase 2: Core Themes (Publications 2-8)

| Pub # | Title                    | Related Posts     | Key Topics                                                                               |
| ----- | ------------------------ | ----------------- | ---------------------------------------------------------------------------------------- |
| 2     | System Integration       | 1, 11, 14, 16, 17 | 92% integration challenges, 40-50% deployment time, MCP, enterprise systems              |
| 3     | Context Management       | 1, 10, 24         | 40% utilization rule, context quality vs capacity, memory architecture                   |
| 4     | Framework Abandonment    | 1, 8, 19, 22      | 80-90% a popular AI agent framework abandonment, 3-4x performance gap, custom frameworks |
| 5     | Demo to Production Chasm | 1, 6, 14, 15      | 70% demo accuracy trap, probabilistic systems, doom loop, stakeholder expectations       |
| 6     | Enterprise Blockers      | 1, 5, 14, 16, 17  | 90% ROI failure, CISO/CIO gatekeepers, pricing confusion, security governance            |
| 7     | Coding Agent Exception   | 1, 8, 20          | Only two killer apps (search, coding), 3x productivity gains, generation vs analysis     |
| 8     | Model Myth               | 1, 4, 7, 22       | 30-40% model contribution, 60-70% framework importance, architecture > model             |

### Phase 3: Emergent Insights (Publications 9-13)

| Pub # | Title                      | Related Posts    | Key Topics                                                                  |
| ----- | -------------------------- | ---------------- | --------------------------------------------------------------------------- |
| 9     | Handoff Rate Metric        | 1, 6, 13, 23     | North star metric, 90% pilot failure, smart FAQs vs agents                  |
| 10    | Dual Memory Architecture   | 1, 3, 18, 24     | User memory vs agent memory, PII governance, different stakeholders         |
| 11    | MCP 25-Tool Cliff          | 1, 2, 16, 21, 23 | 30% accuracy beyond 25 tools, context bloat, enterprise scale               |
| 12    | Component-Level Evaluation | 1, 13, 18        | End-to-end testing failure, first-step retrieval, 59% pipeline accuracy     |
| 13    | Evaluation Gap Market      | 1, 9, 12, 18     | 7 YC companies zero adoption, process vs outcome metrics, $10B+ opportunity |

### Phase 4: Practitioner Perspectives (Publications 14-18)

| Pub # | Title                                         | Related Posts | Key Topics                                                                           |
| ----- | --------------------------------------------- | ------------- | ------------------------------------------------------------------------------------ |
| 14    | an AI agent orchestration company Interview   | 1, 2, 5, 6    | 90% pilot failure, undefined ROI, 25+ production use cases, custom deployments       |
| 15    | an AI infrastructure company Interview        | 1, 5, 24      | 70% demo success rate, doom loop, deterministic conditioning, scientific methodology |
| 16    | a major enterprise identity company Interview | 1, 2, 6, 11   | Agent identity, next SSO moment, MCP extensions, CISO gatekeepers                    |
| 17    | a multi-agent framework company Interview     | 1, 2, 6       | Enterprise topology, $2M savings, 40-country complexity, labor law strategy          |
| 18    | an AI sales intelligence company Interview    | 1, 10, 12, 13 | Vertical AI, 60M to 20 data points, component evaluation, retrieval as moat          |

### Phase 5: Prototype Learnings (Publications 19-21)

| Pub # | Title          | Related Posts | Key Topics                                                                           |
| ----- | -------------- | ------------- | ------------------------------------------------------------------------------------ |
| 19    | Shopping Agent | 1, 4, 11      | Framework switch mid-project, LangGraph to a popular AI agent framework, MCP mocking |
| 20    | Repo Patcher   | 1, 7, 5       | State machines, HITL escalation, 6-stage workflow, $0.25 cost target                 |
| 21    | Good Agents    | 1, 11, 16     | Plan-Verify-Execute, SSE streaming, OAuth/RBAC security, governed automation         |

### Phase 6: Conference Insights (Publications 22-24)

| Pub # | Title                                   | Related Posts | Key Topics                                                                    |
| ----- | --------------------------------------- | ------------- | ----------------------------------------------------------------------------- |
| 22    | an AI autonomous agent company Fireside | 1, 4, 8       | 30-40% model revelation, multi-model orchestration, 8x cost reduction         |
| 23    | Why 95% Fail Conference                 | 1, 9, 11      | Four traps taxonomy, RAG chatbots, handoff rate, MCP context bloat            |
| 24    | Production Agents Summit                | 1, 3, 10, 15  | 40% context rule, context engineering, notes summarization, left turn problem |

### Phase 7: Methodology (Publication 25)

| Pub # | Title                | Related Posts | Key Topics                                                                     |
| ----- | -------------------- | ------------- | ------------------------------------------------------------------------------ |
| 25    | Research Methodology | 1-24          | 44 sources, 35 parallel agents, two-phase extraction, theme frequency analysis |

---

## Topic Cross-Reference

### AI Agents (General)

**Posts:** 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25
**Description:** All publications address AI agent development and deployment

### System Integration

**Posts:** 1, 2, 14, 16, 17
**Description:** 92% of deployments struggle with integration; 40-50% of time spent on integration work

### MCP (Model Context Protocol)

**Posts:** 2, 11, 16, 19, 21, 23
**Description:** 25-tool accuracy cliff, context bloat, enterprise limitations, integration challenges

### Framework Abandonment

**Posts:** 1, 4, 8, 19, 22
**Description:** 80-90% of teams abandon a popular AI agent framework for production; custom solutions outperform

### Enterprise Adoption/Blockers

**Posts:** 1, 5, 6, 14, 16, 17
**Description:** ROI calculation failures, CISO/CIO gatekeepers, pricing confusion, security requirements

### Context Management

**Posts:** 1, 3, 10, 18, 24
**Description:** 40% utilization rule, context quality vs capacity, compression strategies

### Memory Architecture

**Posts:** 3, 10, 18, 24
**Description:** User memory vs agent memory distinction, PII governance, retrieval strategies

### Model vs Framework Contribution

**Posts:** 1, 4, 7, 8, 22
**Description:** 30-40% model contribution vs 60-70% framework/architecture importance

### Evaluation & Testing

**Posts:** 5, 9, 12, 13, 18
**Description:** End-to-end testing limitations, component-level evaluation, LLM-as-judge failures

### Handoff Rate Metric

**Posts:** 9, 13, 23
**Description:** North star metric for AI agent success; measures human task reduction

### Probabilistic Systems

**Posts:** 5, 12, 15, 20, 24
**Description:** Demo to production chasm, deterministic governance, doom loop, scientific methodology

### Coding Agents

**Posts:** 7, 20
**Description:** Exception case with product-market fit; 3x productivity gains; generation vs analysis

### Production Deployment

**Posts:** 1, 5, 6, 14, 15, 17, 19, 20, 21, 24
**Description:** Practical challenges, cost targets, state machines, reliability patterns

### ROI/Business Case

**Posts:** 1, 6, 14, 17
**Description:** 90% failure from undefined ROI; economics before engineering

### Pricing Models

**Posts:** 6, 16
**Description:** Token-based vs seat-based vs outcome-based; $400-750 willingness vs $20 sustainable

### Security & Governance

**Posts:** 6, 16, 21
**Description:** CISO gatekeepers, OAuth/RBAC, PII redaction, AES-256 encryption

### Agent Identity

**Posts:** 16, 21
**Description:** Next SSO moment; authentication for non-human actors

### Vertical AI

**Posts:** 7, 18
**Description:** Vertical wins over horizontal; domain specialization as competitive moat

### State Machines

**Posts:** 5, 20, 21
**Description:** Deterministic governance over probabilistic behavior; predictable flow patterns

### Human-in-the-Loop (HITL)

**Posts:** 9, 20, 21
**Description:** Risk-based escalation; responsible design pattern; governance mechanism

### Multi-Agent Systems

**Posts:** 21, 22, 25
**Description:** Plan-Verify-Execute pattern, multi-model orchestration, parallel processing

### RAG (Retrieval-Augmented Generation)

**Posts:** 3, 12, 18, 23, 24
**Description:** Just-in-time retrieval, first-step retrieval importance, RAG chatbot trap

### Knowledge Graphs

**Posts:** 18
**Description:** Structured graphs vs LLM-generated; schema-defined approaches

### Cost Optimization

**Posts:** 17, 20, 22
**Description:** 8x cost reduction, $0.25 per fix target, caching strategies

### Enterprise Scale

**Posts:** 2, 11, 16, 17
**Description:** 40-country operations, 100K+ employees, heterogeneous tech stacks

### YC/Startup Ecosystem

**Posts:** 13
**Description:** 7 YC eval tools with zero adoption; market opportunity analysis

### Conference Insights

**Posts:** 22, 23, 24
**Description:** an AI autonomous agent company Fireside, Why 95% Fail, Production Agents Summit learnings

### Prototype Learnings

**Posts:** 19, 20, 21
**Description:** First-person build experiences validating research findings

### Practitioner Interviews

**Posts:** 14, 15, 16, 17, 18
**Description:** an AI agent orchestration company, an AI infrastructure company, a major enterprise identity company, a multi-agent framework company, an AI sales intelligence company perspectives

### Research Methodology

**Posts:** 1, 25
**Description:** 36 interviews, 5 conferences, 3 prototypes, systematic analysis

### Demo vs Production

**Posts:** 1, 5, 14, 15
**Description:** 70% demo trap, false stakeholder expectations, production chasm

### Tool Selection/Limits

**Posts:** 2, 11, 23
**Description:** 25-tool accuracy cliff, 30% degradation, context bloat from definitions

---

## Recommended Reading Paths

### For Engineering Leaders

1. **Start:** Anchor (Pub 1) - Overview of all findings
2. **Then:** Model Myth (Pub 8) - Why architecture matters more than model selection
3. **Then:** Framework Abandonment (Pub 4) - Production framework decisions
4. **Then:** Repo Patcher (Pub 20) - State machine patterns for reliability
5. **Then:** Good Agents (Pub 21) - Plan-Verify-Execute governance pattern
6. **Finally:** Production Agents Summit (Pub 24) - 40% context rule and practical deployment

### For Product Managers

1. **Start:** Anchor (Pub 1) - Overview and key statistics
2. **Then:** Demo to Production Chasm (Pub 5) - Managing stakeholder expectations
3. **Then:** Enterprise Blockers (Pub 6) - Why pilots fail (ROI focus)
4. **Then:** Handoff Rate Metric (Pub 9) - The metric that actually matters
5. **Then:** Coding Agent Exception (Pub 7) - Where AI agents work today
6. **Finally:** an AI agent orchestration company Interview (Pub 14) - Practitioner perspective on deployment

### For Researchers

1. **Start:** Anchor (Pub 1) - Research overview and methodology
2. **Then:** Research Methodology (Pub 25) - Systematic analysis approach
3. **Then:** Evaluation Gap Market (Pub 13) - Evaluation challenges
4. **Then:** Component-Level Evaluation (Pub 12) - Testing methodologies
5. **Then:** Context Management (Pub 3) - 40% utilization research
6. **Finally:** an AI autonomous agent company Fireside (Pub 22) - Primary source insights

### For Enterprise Architects

1. **Start:** Anchor (Pub 1) - Overview of production challenges
2. **Then:** System Integration (Pub 2) - 92% integration challenge
3. **Then:** MCP 25-Tool Cliff (Pub 11) - Protocol limitations at scale
4. **Then:** a major enterprise identity company Interview (Pub 16) - Agent identity and SSO
5. **Then:** a multi-agent framework company Interview (Pub 17) - Enterprise topology complexity
6. **Finally:** Dual Memory Architecture (Pub 10) - Memory system design

### For Startup Founders

1. **Start:** Anchor (Pub 1) - Market reality check
2. **Then:** Evaluation Gap Market (Pub 13) - $10B+ opportunity
3. **Then:** Coding Agent Exception (Pub 7) - Where PMF exists
4. **Then:** an AI sales intelligence company Interview (Pub 18) - Vertical AI success story
5. **Then:** Framework Abandonment (Pub 4) - Build vs buy decisions
6. **Finally:** Why 95% Fail (Pub 23) - Four traps to avoid

### For DevOps/MLOps Teams

1. **Start:** Anchor (Pub 1) - Production deployment overview
2. **Then:** Repo Patcher (Pub 20) - State machine reliability patterns
3. **Then:** Shopping Agent (Pub 19) - Framework migration lessons
4. **Then:** Production Agents Summit (Pub 24) - Context management in production
5. **Then:** Component-Level Evaluation (Pub 12) - Testing strategies
6. **Finally:** Good Agents (Pub 21) - Security and observability patterns

---

## Quick Reference

| #   | Title                                         | Type         | Primary Theme | Key Statistic                               |
| --- | --------------------------------------------- | ------------ | ------------- | ------------------------------------------- |
| 1   | Anchor - Research Overview                    | Anchor       | All Themes    | 90% pilot failure rate                      |
| 2   | System Integration                            | Core Theme   | Integration   | 92% struggle with integration               |
| 3   | Context Management                            | Core Theme   | Context       | 40% utilization rule                        |
| 4   | Framework Abandonment                         | Core Theme   | Frameworks    | 80-90% abandon a popular AI agent framework |
| 5   | Demo to Production Chasm                      | Core Theme   | Probabilistic | 70% demo accuracy trap                      |
| 6   | Enterprise Blockers                           | Core Theme   | Enterprise    | 90% fail from undefined ROI                 |
| 7   | Coding Agent Exception                        | Core Theme   | Use Cases     | Only 2 killer apps                          |
| 8   | Model Myth                                    | Core Theme   | Architecture  | 30-40% model contribution                   |
| 9   | Handoff Rate Metric                           | Emergent     | Metrics       | North star for success                      |
| 10  | Dual Memory Architecture                      | Emergent     | Memory        | User vs agent memory                        |
| 11  | MCP 25-Tool Cliff                             | Emergent     | MCP           | 30% accuracy beyond 25 tools                |
| 12  | Component-Level Evaluation                    | Emergent     | Evaluation    | 59% end-to-end accuracy                     |
| 13  | Evaluation Gap Market                         | Emergent     | Evaluation    | 7 YC tools, zero adoption                   |
| 14  | an AI agent orchestration company Interview   | Practitioner | Enterprise    | 25+ production deployments                  |
| 15  | an AI infrastructure company Interview        | Practitioner | Probabilistic | 70% demo success rate                       |
| 16  | a major enterprise identity company Interview | Practitioner | Identity      | Next SSO moment                             |
| 17  | a multi-agent framework company Interview     | Practitioner | Enterprise    | $2M saved, one use case                     |
| 18  | an AI sales intelligence company Interview    | Practitioner | Vertical AI   | 60M to 20 data points                       |
| 19  | Shopping Agent                                | Prototype    | Frameworks    | Framework switch mid-project                |
| 20  | Repo Patcher                                  | Prototype    | Reliability   | 6-stage state machine                       |
| 21  | Good Agents                                   | Prototype    | Governance    | Plan-Verify-Execute                         |
| 22  | an AI autonomous agent company Fireside       | Conference   | Architecture  | 8x cost reduction                           |
| 23  | Why 95% Fail                                  | Conference   | Traps         | Four failure traps                          |
| 24  | Production Agents Summit                      | Conference   | Context       | 40% context ceiling                         |
| 25  | Research Methodology                          | Methodology  | Process       | 35 parallel agents                          |

---

## Publication Type Distribution

| Type                      | Publications        | Count |
| ------------------------- | ------------------- | ----- |
| Anchor                    | 1                   | 1     |
| Core Themes               | 2, 3, 4, 5, 6, 7, 8 | 7     |
| Emergent Insights         | 9, 10, 11, 12, 13   | 5     |
| Practitioner Perspectives | 14, 15, 16, 17, 18  | 5     |
| Prototype Learnings       | 19, 20, 21          | 3     |
| Conference Insights       | 22, 23, 24          | 3     |
| Methodology               | 25                  | 1     |

---

## Key Statistics Referenced Across Publications

| Statistic                   | Value    | Publications       |
| --------------------------- | -------- | ------------------ |
| Pilot failure rate          | 90%      | 1, 5, 6, 9, 14     |
| Model contribution          | 30-40%   | 1, 4, 7, 8, 19, 22 |
| Framework contribution      | 60-70%   | 1, 4, 8, 22        |
| Integration time            | 40-50%   | 1, 2, 8, 14        |
| Framework abandonment       | 80-90%   | 1, 4, 19           |
| MCP tool limit              | 25 tools | 2, 11, 23          |
| MCP accuracy drop           | 30%      | 11, 23             |
| Context utilization ceiling | 40%      | 3, 11, 24          |
| Demo accuracy trap          | 70%      | 5, 15              |
| System integration struggle | 92%      | 2, 25              |

---

## Index Metadata

- **Total Publications:** 25
- **Total Topics Indexed:** 32
- **Reading Paths Defined:** 6
- **Key Statistics Tracked:** 10
- **Cross-References Created:** 150+

_This index was generated to support navigation of the AI Agents Research Publishing Project, enabling readers to explore related content by theme, topic, or role-based learning path._
