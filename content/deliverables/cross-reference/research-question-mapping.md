# Publication to Research Question Mapping

**AI Agents Research Publishing Project**
**Generated: December 3, 2025**
**Total Publications: 25**

---

## Research Questions

Based on original research specification (README.md, spec.txt):

- **RQ1**: What capabilities and constraints define state-of-the-art AI agents today (planning, tool use, memory, multi-step reliability)?

- **RQ2**: What integration layers (e.g., function-calling, tool bridges/"model-context" protocols, event queues, RPA) are most viable for enterprise workflows?

- **RQ3**: What governance patterns (human-in-the-loop, audit, safe action spaces) enable trustworthy deployment?

- **RQ4**: What metrics correlate with business value (success rate, time-to-completion, latency, cost/task, operator workload)?

---

## Mapping Matrix

| Pub # | Publication Title                                               | RQ1 | RQ2 | RQ3 | RQ4 | Primary Focus |
| ----- | --------------------------------------------------------------- | --- | --- | --- | --- | ------------- |
| 1     | Anchor - AI Agents Research Overview                            | X   | X   | X   | X   | Overview      |
| 2     | System Integration (92% struggle)                               |     | X   |     |     | RQ2           |
| 3     | Context Management (40% rule)                                   | X   |     |     |     | RQ1           |
| 4     | Framework Abandonment (80-90% a popular AI agent framework)     | X   | X   |     |     | RQ1/RQ2       |
| 5     | Demo-Production Chasm (70% accuracy)                            | X   |     | X   | X   | RQ1           |
| 6     | Enterprise Blockers (ROI failure)                               |     |     | X   | X   | RQ4           |
| 7     | Coding Agent Exception                                          | X   |     |     | X   | RQ1           |
| 8     | Model Myth (30-40% contribution)                                | X   | X   |     |     | RQ1           |
| 9     | Handoff Rate Metric                                             |     |     |     | X   | RQ4           |
| 10    | Dual Memory Architecture                                        | X   |     |     |     | RQ1           |
| 11    | MCP 25-Tool Cliff                                               |     | X   |     |     | RQ2           |
| 12    | Component-Level Evaluation                                      | X   |     | X   | X   | RQ3           |
| 13    | Evaluation Gap Market                                           |     |     | X   | X   | RQ4           |
| 14    | an AI agent orchestration company Interview (90% pilot failure) |     | X   | X   | X   | RQ4           |
| 15    | an AI infrastructure company Interview (probabilistic)          | X   |     | X   |     | RQ1/RQ3       |
| 16    | a major enterprise identity company Interview (identity)        |     | X   | X   |     | RQ2/RQ3       |
| 17    | a multi-agent framework company Interview (topology)            |     | X   |     | X   | RQ2           |
| 18    | an AI sales intelligence company Interview (vertical AI)        | X   |     | X   | X   | RQ1/RQ4       |
| 19    | Shopping Agent Prototype                                        | X   | X   |     |     | RQ1/RQ2       |
| 20    | Repo Patcher Prototype (state machines)                         | X   |     | X   | X   | RQ3           |
| 21    | Good Agents Prototype (Plan-Verify-Execute)                     | X   | X   | X   |     | RQ3           |
| 22    | an AI autonomous agent company Fireside Conference              | X   | X   |     | X   | RQ1           |
| 23    | Why 95% Fail Conference                                         |     | X   | X   | X   | RQ4           |
| 24    | Production Agents Summit                                        | X   |     | X   |     | RQ1/RQ3       |
| 25    | Research Methodology                                            | X   | X   | X   | X   | Overview      |

---

## Research Question Coverage

### RQ1: Agent Capabilities and Constraints

**Publications:** 17 of 25 (68%)

| Pub # | Title                                      | Key RQ1 Content                                                  |
| ----- | ------------------------------------------ | ---------------------------------------------------------------- |
| 1     | Anchor                                     | 30-40% model contribution, multi-step reliability findings       |
| 3     | Context Management                         | 40% context utilization rule, memory architecture                |
| 4     | Framework Abandonment                      | Framework capabilities vs custom solutions, 3-4x performance gap |
| 5     | Demo-Production Chasm                      | 70% demo accuracy, doom loop in multi-step reliability           |
| 7     | Coding Agent Exception                     | Generation vs analysis capability asymmetry, 3x productivity     |
| 8     | Model Myth                                 | Model contributes 30-40%, framework 60-70% of success            |
| 10    | Dual Memory Architecture                   | User memory vs agent memory distinction                          |
| 12    | Component-Level Evaluation                 | First-step retrieval importance, 59% pipeline accuracy           |
| 15    | an AI infrastructure company Interview     | Probabilistic system constraints, deterministic conditioning     |
| 18    | an AI sales intelligence company Interview | Vertical AI capabilities, data moat for reliability              |
| 19    | Shopping Agent                             | Framework capabilities tested hands-on                           |
| 20    | Repo Patcher                               | Multi-step reliability patterns, state machine approach          |
| 21    | Good Agents                                | Plan-Verify-Execute pattern for reliability                      |
| 22    | an AI autonomous agent company Fireside    | Multi-model orchestration, model selection strategies            |
| 24    | Production Agents Summit                   | Context engineering, sub-agent patterns                          |
| 25    | Research Methodology                       | Prototype validation of capabilities                             |

### RQ2: Integration Layers

**Publications:** 13 of 25 (52%)

| Pub # | Title                                         | Key RQ2 Content                                                          |
| ----- | --------------------------------------------- | ------------------------------------------------------------------------ |
| 1     | Anchor                                        | 92% integration challenges, 40-50% deployment time                       |
| 2     | System Integration                            | MCP limitations, heterogeneous tech stacks, custom integration as moat   |
| 4     | Framework Abandonment                         | a popular AI agent framework abandonment, framework bloat in integration |
| 8     | Model Myth                                    | Framework/system architecture importance                                 |
| 11    | MCP 25-Tool Cliff                             | 30% accuracy beyond 25 tools, context bloat                              |
| 14    | an AI agent orchestration company Interview   | SAP, Salesforce integration challenges                                   |
| 16    | a major enterprise identity company Interview | MCP extensions, agent identity for integration                           |
| 17    | a multi-agent framework company Interview     | 40-country enterprise topology complexity                                |
| 19    | Shopping Agent                                | MCP mocking, framework integration testing                               |
| 21    | Good Agents                                   | MCP integration challenges, SSE streaming                                |
| 22    | an AI autonomous agent company Fireside       | Multi-agent orchestration protocols                                      |
| 23    | Why 95% Fail                                  | MCP context bloat trap, tool definition overhead                         |
| 25    | Research Methodology                          | Integration layer validation through prototypes                          |

### RQ3: Governance Patterns

**Publications:** 14 of 25 (56%)

| Pub # | Title                                         | Key RQ3 Content                                    |
| ----- | --------------------------------------------- | -------------------------------------------------- |
| 1     | Anchor                                        | HITL requirements, enterprise governance reality   |
| 5     | Demo-Production Chasm                         | Stakeholder expectation management                 |
| 6     | Enterprise Blockers                           | CISO/CIO gatekeepers, audit requirements, security |
| 12    | Component-Level Evaluation                    | Testing governance, deterministic validation       |
| 13    | Evaluation Gap                                | Process vs outcome governance                      |
| 14    | an AI agent orchestration company Interview   | Enterprise governance patterns in production       |
| 15    | an AI infrastructure company Interview        | Scientific methodology for governance              |
| 16    | a major enterprise identity company Interview | Agent identity, authentication, SSO patterns       |
| 18    | an AI sales intelligence company Interview    | PII governance, enterprise sales compliance        |
| 20    | Repo Patcher                                  | HITL escalation, risk-based governance             |
| 21    | Good Agents                                   | OAuth/RBAC security, governed automation           |
| 23    | Why 95% Fail                                  | Governance traps to avoid                          |
| 24    | Production Agents Summit                      | Enterprise security, observability requirements    |
| 25    | Research Methodology                          | Governance validation through prototypes           |

### RQ4: Business Value Metrics

**Publications:** 14 of 25 (56%)

| Pub # | Title                                       | Key RQ4 Content                                               |
| ----- | ------------------------------------------- | ------------------------------------------------------------- |
| 1     | Anchor                                      | 90% pilot failure, ROI as primary failure mode                |
| 5     | Demo-Production Chasm                       | Demo vs production success gap                                |
| 6     | Enterprise Blockers                         | $400-750 willingness to pay, ROI undefined, pricing confusion |
| 7     | Coding Agent Exception                      | 3x productivity for coding agents                             |
| 9     | Handoff Rate Metric                         | North star metric, human task reduction                       |
| 12    | Component-Level Evaluation                  | 59% accuracy, testable metrics                                |
| 13    | Evaluation Gap                              | $10B+ market opportunity, zero adoption on 7 YC tools         |
| 14    | an AI agent orchestration company Interview | 90% pilot failure from undefined ROI                          |
| 17    | a multi-agent framework company Interview   | $2M single use case savings, $100M target                     |
| 18    | an AI sales intelligence company Interview  | Revenue operations ROI                                        |
| 20    | Repo Patcher                                | $0.25 per fix cost target                                     |
| 22    | an AI autonomous agent company Fireside     | 8x cost reduction strategies                                  |
| 23    | Why 95% Fail                                | Four traps taxonomy, handoff rate focus                       |
| 25    | Research Methodology                        | Quantitative analysis approach                                |

---

## Coverage Summary

| Research Question                   | Publication Count | Coverage % |
| ----------------------------------- | ----------------- | ---------- |
| RQ1: Agent Capabilities/Constraints | 17                | 68%        |
| RQ2: Integration Layers             | 13                | 52%        |
| RQ3: Governance Patterns            | 14                | 56%        |
| RQ4: Business Value Metrics         | 14                | 56%        |

### Distribution by Publication Type

| Type                              | RQ1 | RQ2 | RQ3 | RQ4 |
| --------------------------------- | --- | --- | --- | --- |
| Anchor (1)                        | 1   | 1   | 1   | 1   |
| Core Themes (2-8)                 | 6   | 4   | 2   | 3   |
| Emergent Insights (9-13)          | 2   | 1   | 3   | 4   |
| Practitioner Perspectives (14-18) | 3   | 4   | 4   | 4   |
| Prototype Learnings (19-21)       | 3   | 2   | 2   | 1   |
| Conference Insights (22-24)       | 2   | 2   | 2   | 2   |
| Methodology (25)                  | 1   | 1   | 1   | 1   |

---

## Coverage Analysis

### Strengths

1. **RQ1 (Agent Capabilities) - 68% coverage**: Best represented across the publication series. This aligns with the research's core technical focus. Strong coverage in:
   - Core theme publications (especially 3, 4, 5, 7, 8)
   - All three prototype publications
   - Conference insights

2. **Balanced RQ3/RQ4 coverage (56% each)**: Governance patterns and business value metrics are equally well-represented, reflecting the research finding that "production AI agents are an engineering AND business problem."

3. **Cross-cutting publications**: Publications 1, 20, 21, and 25 address all four research questions, providing comprehensive entry points for readers.

4. **Practitioner perspectives well-distributed**: All 5 practitioner interviews address 3+ research questions, providing real-world validation across all research dimensions.

### Areas for Consideration

1. **RQ2 (Integration Layers) - 52% coverage**: Lowest coverage among research questions. However, this is offset by:
   - Publication 2 (System Integration) being a comprehensive deep dive
   - MCP-specific content in publications 11, 19, 21, 23
   - Integration being a cross-cutting theme in many publications

2. **Prototype publications**: While strong on RQ1 and RQ3, fewer direct connections to RQ4 (business metrics). The cost targets in Repo Patcher ($0.25/fix) partially address this.

---

## Gaps Identified

### Minor Gaps (adequately addressed but could be expanded)

1. **RQ2 in Emergent Insights**: Only Publication 11 (MCP 25-Tool Cliff) directly addresses integration layers in the emergent insights category. Consider cross-linking other emergent insights to integration implications.

2. **RQ4 in Prototype Learnings**: Business value metrics less prominent in prototype publications. Only Repo Patcher explicitly mentions cost targets. Consider adding ROI analysis sections to Shopping Agent and Good Agents posts.

### No Significant Gaps Identified

All four research questions are substantially covered:

- Every RQ is addressed by 13+ publications (52%+)
- Each publication type (except anchor/methodology) contributes to multiple RQs
- No research question is systematically underrepresented

---

## Recommendations

### Cross-Linking Strategy by RQ

**For RQ1 readers**: Start with Anchor (1) -> Model Myth (8) -> Context Management (3) -> Coding Agent Exception (7) -> Repo Patcher (20)

**For RQ2 readers**: Start with Anchor (1) -> System Integration (2) -> MCP 25-Tool Cliff (11) -> a major enterprise identity company Interview (16) -> Good Agents (21)

**For RQ3 readers**: Start with Anchor (1) -> Enterprise Blockers (6) -> Repo Patcher (20) -> Good Agents (21) -> a major enterprise identity company Interview (16)

**For RQ4 readers**: Start with Anchor (1) -> Enterprise Blockers (6) -> Handoff Rate Metric (9) -> an AI agent orchestration company Interview (14) -> Why 95% Fail (23)

### Suggested Enhancements

1. Add "Research Questions Addressed" section to each blog post footer
2. Create RQ-based filtering on the series landing page
3. Include RQ callout boxes when citing key statistics

---

## Detailed Publication-RQ Mapping

### Category 1: Anchor Publication

| #   | Title                       | RQ1 | RQ2 | RQ3 | RQ4 | Notes                                                                               |
| --- | --------------------------- | --- | --- | --- | --- | ----------------------------------------------------------------------------------- |
| 1   | AI Agents Research Overview | X   | X   | X   | X   | Comprehensive overview addresses all RQs; serves as hub for RQ-specific exploration |

### Category 2: Theme Deep Dives

| #   | Title                  | RQ1 | RQ2 | RQ3 | RQ4 | Notes                                                                           |
| --- | ---------------------- | --- | --- | --- | --- | ------------------------------------------------------------------------------- |
| 2   | System Integration     |     | X   |     |     | Primary RQ2 publication; 92% struggle statistic; MCP limitations                |
| 3   | Context Management     | X   |     |     |     | Memory architecture relates to agent capabilities (RQ1)                         |
| 4   | Framework Abandonment  | X   | X   |     |     | Framework capabilities (RQ1) and integration bloat (RQ2)                        |
| 5   | Demo-Production Chasm  | X   |     | X   | X   | Probabilistic reliability (RQ1), governance (RQ3), demo vs production gap (RQ4) |
| 6   | Enterprise Blockers    |     |     | X   | X   | CISO governance (RQ3), ROI metrics (RQ4)                                        |
| 7   | Coding Agent Exception | X   |     |     | X   | Capability asymmetry (RQ1), productivity gains (RQ4)                            |
| 8   | Model Myth             | X   | X   |     |     | Core RQ1 finding; framework architecture (RQ2)                                  |

### Category 3: Emergent Insights

| #   | Title                      | RQ1 | RQ2 | RQ3 | RQ4 | Notes                                                       |
| --- | -------------------------- | --- | --- | --- | --- | ----------------------------------------------------------- |
| 9   | Handoff Rate Metric        |     |     |     | X   | Primary RQ4 publication; north star metric definition       |
| 10  | Dual Memory Architecture   | X   |     |     |     | Memory as agent capability constraint (RQ1)                 |
| 11  | MCP 25-Tool Cliff          |     | X   |     |     | Integration layer limitation (RQ2)                          |
| 12  | Component-Level Evaluation | X   |     | X   | X   | Testing capabilities (RQ1), governance (RQ3), metrics (RQ4) |
| 13  | Evaluation Gap Market      |     |     | X   | X   | Evaluation governance (RQ3), market opportunity (RQ4)       |

### Category 4: Practitioner Perspectives

| #   | Title                                         | RQ1 | RQ2 | RQ3 | RQ4 | Notes                                                               |
| --- | --------------------------------------------- | --- | --- | --- | --- | ------------------------------------------------------------------- |
| 14  | an AI agent orchestration company Interview   |     | X   | X   | X   | Integration challenges (RQ2), governance (RQ3), ROI failure (RQ4)   |
| 15  | an AI infrastructure company Interview        | X   |     | X   |     | Probabilistic constraints (RQ1), scientific governance (RQ3)        |
| 16  | a major enterprise identity company Interview |     | X   | X   |     | Identity integration (RQ2), authentication governance (RQ3)         |
| 17  | a multi-agent framework company Interview     |     | X   |     | X   | Enterprise topology (RQ2), $2M savings (RQ4)                        |
| 18  | an AI sales intelligence company Interview    | X   |     | X   | X   | Vertical capabilities (RQ1), PII governance (RQ3), RevOps ROI (RQ4) |

### Category 5: Prototype Learnings

| #   | Title          | RQ1 | RQ2 | RQ3 | RQ4 | Notes                                                                 |
| --- | -------------- | --- | --- | --- | --- | --------------------------------------------------------------------- |
| 19  | Shopping Agent | X   | X   |     |     | Framework capabilities (RQ1), MCP integration (RQ2)                   |
| 20  | Repo Patcher   | X   |     | X   | X   | Multi-step reliability (RQ1), HITL governance (RQ3), $0.25 cost (RQ4) |
| 21  | Good Agents    | X   | X   | X   |     | PVE pattern (RQ1/RQ3), MCP integration (RQ2), OAuth governance (RQ3)  |

### Category 6: Conference Insights

| #   | Title                                   | RQ1 | RQ2 | RQ3 | RQ4 | Notes                                                       |
| --- | --------------------------------------- | --- | --- | --- | --- | ----------------------------------------------------------- |
| 22  | an AI autonomous agent company Fireside | X   | X   |     | X   | Model selection (RQ1), orchestration (RQ2), 8x cost (RQ4)   |
| 23  | Why 95% Fail                            |     | X   | X   | X   | MCP traps (RQ2), governance traps (RQ3), handoff rate (RQ4) |
| 24  | Production Agents Summit                | X   |     | X   |     | Context engineering (RQ1), enterprise security (RQ3)        |

### Category 7: Methodology

| #   | Title                | RQ1 | RQ2 | RQ3 | RQ4 | Notes                                             |
| --- | -------------------- | --- | --- | --- | --- | ------------------------------------------------- |
| 25  | Research Methodology | X   | X   | X   | X   | Validation of all RQs through systematic analysis |

---

## Index Metadata

- **Total Publications Mapped:** 25
- **Research Questions Tracked:** 4
- **Total RQ Assignments:** 58 (across all publications)
- **Average RQs per Publication:** 2.32
- **Publications Addressing All 4 RQs:** 3 (Publications 1, 25, and partially 12)

_This mapping was generated to support research question traceability for the AI Agents Research Publishing Project, enabling verification that all original research questions are adequately addressed across the 25-publication series._
