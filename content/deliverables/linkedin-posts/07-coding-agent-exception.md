# LinkedIn Post: Publication 7 - The Coding Agent Exception

---

Cursor made coding agents look easy. Don't let that fool you.

After interviewing 36 experts building production AI agents, we found a striking pattern:

Coding agents are the exception, not the rule.

There are really only two killer apps for AI agents right now: search and coding. Everything else is struggling to find product-market fit.

Why does coding work when most agent applications fail?

Here's what the research revealed:

- "Only two killer apps: search and coding agents" (a developer, an AI coding company)
- Coding agents deliver 3x productivity gains, but general agents face 3-5x cost disadvantage vs offshore labor
- Generation (writing code) succeeds; Analysis (knowledge work) still struggles
- Models contribute only 30-40% to success - the framework and system architecture matter far more

The asymmetry is stark. Coding agents generate outputs into a structured environment with immediate feedback loops (tests, compilers, linters). Knowledge work requires analysis of ambiguous inputs with no clear validation path.

This isn't about model intelligence. It's about problem structure.

Full breakdown: [LINK]

What use cases have you found where AI agents actually work?

#AIAgents #CodingAgents #Cursor #LLMs #ProductionAI

---

**Character Count**: ~1,350 characters
**Publication**: 07 - Model Capabilities
**Blog Link**: /blog/coding-agent-exception
